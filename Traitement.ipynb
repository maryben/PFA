{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words as engwords\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(['research', 'subject', 'interest', 'also'])\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words and len(word)>2:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_numbers(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if not word.isdigit():\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(Text):\n",
    "    coumpound_nlp = nlp(Text)\n",
    "\n",
    "    coumpound_word = []\n",
    "    for X in coumpound_nlp.ents:\n",
    "        s = re.sub(r'[^\\w\\s]','',X.text.lower())\n",
    "        s = re.sub(\"[\\s.;:,*]+\", \" \", s)\n",
    "        coumpound_word.append(s)\n",
    "    \n",
    "    tokens = word_tokenize(Text.lower())\n",
    "    fTokens = []\n",
    "    word = ''\n",
    "    for t in tokens:\n",
    "        if word == '':\n",
    "            word = t\n",
    "        else:\n",
    "            word += ' '+t\n",
    "        find = False\n",
    "        for X in coumpound_word:\n",
    "            if word in X:\n",
    "                find = True\n",
    "                if word == X:\n",
    "                    fTokens.append(word)\n",
    "                    word = ''\n",
    "                    break\n",
    "        if find == False:\n",
    "            tokensW = word_tokenize(word)\n",
    "            for w in tokensW:\n",
    "                fTokens.append(w)\n",
    "            word = ''\n",
    "    fTokens = normalize(fTokens)\n",
    "    return fTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "def tf(word, words):\n",
    "    return words.count(word) / len(words)\n",
    "\n",
    "def n_containing(word, wordslist):\n",
    "    return sum(1 for words in wordslist if word in words)\n",
    "\n",
    "def idf(word, wordslist):\n",
    "    return math.log(len(wordslist) / (1 + n_containing(word, wordslist)))\n",
    "\n",
    "def tfidf(word, words, wordslist):\n",
    "    return tf(word, words) * idf(word, wordslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitement(l0, line1, line2, line3, line4):\n",
    "    with open('traitement.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "        words = getTokens(line1)\n",
    "        #print(\"Top interest :\")\n",
    "        scores = {word: tf(word, words) for word in words}\n",
    "        sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        l1 = ' '\n",
    "        for word, score in sorted_words[:3]:\n",
    "            l1 += word+\" \"\n",
    "\n",
    "        line2 = nlp(line2)\n",
    "\n",
    "        #print(\"University :\")\n",
    "        University = []\n",
    "        for X in line2.ents:\n",
    "            if 'university' in X.text.lower(): \n",
    "                University.append(X.text.lower().replace('\\n',''))\n",
    "        l2 = ' '\n",
    "        University = set(University)\n",
    "        for u in University: \n",
    "            l2 +=u+\" \"\n",
    "\n",
    "        l3  = ' '    \n",
    "        #print(\"Advisors :\")\n",
    "        for X in line2.ents:\n",
    "            if X.label_ == 'PERSON':\n",
    "                l3  += X.text.lower().replace('\\n','')+\" \"\n",
    "\n",
    "        l4  = ' '\n",
    "        #print(\"laboratories or research teams\")\n",
    "        line3 = nlp(line3)\n",
    "        for X in line3.ents:\n",
    "            if X.label_ == 'ORG':\n",
    "                l4  += X.text.lower().replace('\\n','')+\" \"\n",
    "\n",
    "        l5 = ' '\n",
    "        #print(\"collaborations\")\n",
    "        line4 = nlp(line4)\n",
    "        collaborations = []\n",
    "        for X in line4.ents:\n",
    "            if X.label_ == 'PERSON':\n",
    "                find = False\n",
    "                for c in collaborations:\n",
    "                    if X.text in c:\n",
    "                        find = True\n",
    "                if find == False:\n",
    "                    collaborations.append(X.text.lower().replace(\"[\\s]+\",' '))\n",
    "\n",
    "        collaborations = normalize(set(collaborations))\n",
    "        for c in collaborations:\n",
    "            l5  += c+\" \"\n",
    "\n",
    "        \n",
    "        theWriter = csv.writer(f)\n",
    "        theWriter.writerow([l0, l1, l2, l3, l4, l5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv\n",
    "#with open('CVs.csv', 'w', newline='') as f:\n",
    "#    theWriter = csv.writer(f)\n",
    "#    theWriter.writerow(['Name', 'Research Interests', 'Education', 'Research Experience', 'Selected Publications'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv\n",
    "#with open('traitement.csv', 'w', newline='', encoding=\"utf-8\") as f:\n",
    "#    theWriter = csv.DictWriter(f, fieldnames=[\"name\",\"interest\", \"University\", \"Advisor\", \"Laboratorie\", \"Collaboration\"])\n",
    "#    theWriter.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = \"\"\" \"\"\"\n",
    "\n",
    "Research_Interests = \"\"\" \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Education = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Research_Experience = \"\"\" \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Selected_Publications = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CVs.csv', 'a', newline='', encoding=\"utf-8\") as f:\n",
    "    theWriter = csv.writer(f)\n",
    "    theWriter.writerow([Name, Research_Interests, Education, Research_Experience, Selected_Publications])\n",
    "    traitement(Name, Research_Interests, Education, Research_Experience, Selected_Publications)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
